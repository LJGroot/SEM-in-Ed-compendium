[["ch2.html", "2 Using lavaan to Run Regression and ANOVA as a SEM 2.1 Prepare Data and Workspace 2.2 Multiple Regression in SEM 2.3 Caveats with SEM 2.4 Multigroup SEM", " 2 Using lavaan to Run Regression and ANOVA as a SEM This chapter prepares the reader to learn about structural equation modeling (SEM) by reviewing the fundamentals of ordinary least-squares (OLS) regression in the general(ized) linear modeling (GLM) framework. Some key take-home messages will reinforce what was discussed about covariance structure analysis in the previous chapter: Analyzing different data formats (raw vs. summary data) yields equivalent results (under conditions of normality and complete data). Recall from the previous chapter that maximum-likelihood estimation (MLE) in SEM chooses parameters that minimize discrepancies between observed and expected summary statistics rather than casewise observations. Grouping variables can be represented as dummy, effects, or contrast codes, but there are some advantages of stratifying results by group. This will be demonstrated using multigroup SEM and comparing results to the single-group approach. Point estimates from SEM will match GLM because OLS estimates are ML estimates when the distributional assumptions are met. independent, identically distributed (normal with homogeneous variance) However, the SEs are typically smaller under ML with SEM than under OLS with GLM. Furthermore, different (but analogous) test statistics will be compared between GLM (t and F statistics) and SEM (z and \\(\\chi^2\\) statistics). Model comparisons require fitting nested models to the same data, which in SEM means fitting them to the same summary statistics. 2.1 Prepare Data and Workspace 2.1.1 Import Example Data We will use data from a tutorial published on the Social Change Lab’s web site. dat &lt;- foreign::read.spss(&quot;demoData/MODMED.sav&quot;, to.data.frame = TRUE)[c(2, 3, 5, 7)] ## Save summary statistics M &lt;- colMeans(dat) S &lt;- cov(dat) N &lt;- nrow(dat) Recall from Chapter 1 that: SEM can equivalently be fitted to summary statistics rather than raw data It is possible to fit a “multigroup SEM” to obtain parameter estimates separately per group This chapter will show how to fit a multigroup SEM to raw data as well as to summary statistics. For the latter, we require group-specific summary statistics, which Chapter 1 discussed how to obtain: ## Create factor from effects-coded conditions dat$mood.f &lt;- factor(dat$MOOD, levels = c(-1, 1), labels = c(&quot;neutral&quot;,&quot;positive&quot;)) ## Save lists of group-specific summary statistics CC &lt;- c(&quot;ATT&quot;,&quot;NFC&quot;,&quot;POS&quot;) # when group = &quot;mood.f&quot; gM &lt;- sapply(c(&quot;neutral&quot;,&quot;positive&quot;), simplify = FALSE, FUN = function(g) colMeans(dat[dat$mood.f == g, CC]) ) gS &lt;- sapply(c(&quot;neutral&quot;,&quot;positive&quot;), simplify = FALSE, FUN = function(g) cov(dat[dat$mood.f == g, CC]) ) gN &lt;- table(dat$mood.f) 2.1.2 Load lavaan into Workspace library(lavaan) 2.2 Multiple Regression in SEM 2.2.1 lavaan Syntax The standard syntax for regression is a formula object. To regress ATTitude on MOOD condition, Need For Cognition, and POSitive thoughts: ATT ~ MOOD + NFC + POS SEM is a multivariate modeling framework There can be many outcome variables, each with its own formula Outcomes can also predict other outcomes There can be unobserved (latent) variables So lavaan requires collecting these simultaneous equations in a character vector, even when there is only one outcome &#39; ATT ~ MOOD + NFC + POS &#39; 2.2.1.1 OLS Regression Using the familiar lm() function to obtain OLS estimates of a regression model: ols &lt;- lm(ATT ~ MOOD + NFC + POS, data = dat) summary(ols) ## ## Call: ## lm(formula = ATT ~ MOOD + NFC + POS, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -40.061 -8.440 -0.417 8.718 28.010 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.9807 1.3107 1.511 0.134 ## MOOD 1.8839 1.5388 1.224 0.224 ## NFC 0.8884 0.9422 0.943 0.348 ## POS 1.1406 0.1862 6.126 1.98e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 13.11 on 96 degrees of freedom ## Multiple R-squared: 0.4094, Adjusted R-squared: 0.3909 ## F-statistic: 22.18 on 3 and 96 DF, p-value: 5.382e-11 2.2.1.2 MLE in lavaan with Raw or Summary Data When data are complete, maximum likelihood estimation (MLE) provides equivalent results using either raw or summary data. There are multiple model-fitting functions in lavaan: lavaan() is the main “engine”, but expects that models are fully specified in complete detail sem() is a “wrapper” that calls lavaan() with some sensible defaults that apply to most SEMs (e.g., automatically estimating residual variances, automatically estimating covariances among predictors) cfa() is meant for fitting confirmatory factor analysis (CFA) models, discussed in a later chapter. cfa() and sem() actually behave identically (i.e., they call lavaan() with the same defaults) growth() is meant for very simple latent growth curve models, also discussed in a later chapter For now, we will use the sem() function similar to the way we use the lm() function, including how we obtain results from summary(). ## Raw Data mle &lt;- sem(&#39;ATT ~ MOOD + NFC + POS&#39;, data = dat, meanstructure = TRUE) # explicitly request intercept ## Summary Data mle &lt;- sem(&#39;ATT ~ MOOD + NFC + POS&#39;, sample.nobs = N, sample.cov = S, sample.mean = M) Now inspect the output. Identify each parameter estimate, and compare it to the corresponding OLS estimate in the lm() results. summary(mle, header = FALSE, nd = 4) # rsquare = TRUE also available ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## ATT ~ ## MOOD 1.8839 1.5077 1.2495 0.2115 ## NFC 0.8884 0.9232 0.9623 0.3359 ## POS 1.1406 0.1824 6.2519 0.0000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .ATT 1.9807 1.2842 1.5424 0.1230 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .ATT 164.9191 23.3231 7.0711 0.0000 sigma(ols)^2 # compare to residual variance from OLS ## [1] 171.7908 2.2.1.3 Compare/Contrast Estimates lavaan’s point estimates match OLS, except residual variance (\\(\\sigma^2_\\varepsilon\\)) OLS estimates \\(\\sigma^2_\\varepsilon\\) by dividing the residual \\(SS\\) by the residual \\(df\\) SEM estimators choose estimates that reproduce \\(\\bar{\\mathrm{y}}\\) and \\(S\\) If we calculate variance of the residuals (\\(\\mathrm{y}_i - \\hat{\\mathrm{y}}\\)) using the “population formula” (dividing by \\(N\\)), we obtain lavaan’s result sigma(ols)^2 # residual variance from OLS ## [1] 171.7908 sum(resid(ols)^2) / N # manually calculated using POPULATION formula ## [1] 164.9191 coef(mle)[[&quot;ATT~~ATT&quot;]] # matches lavaan ## [1] 164.9191 Note: The double-tilde (~~) operator signifies a two-headed arrow, in contrast to the one-headed arrow (~) of a directed effect 2.2.1.4 Compare/Contrast \\(SE\\)s The estimated \\(SE\\)s are smaller from lavaan because SEM is an asymptotic method estimator assumes \\(N\\) is sufficiently large that \\(S \\approx \\Sigma\\) Wald \\(z\\) statistics replace OLS’s \\(t\\) statistics Model comparison results in a \\(\\chi^2\\) rather than \\(F\\) statistic The asymptotic assumption yields more power, but inflated Type I error rates when sample size is low (relative to number of estimated parameters). Note that lavaan simply calculates sample.cov= and sample.mean= from data=, but they can be passed directly. Also note that raw data= are required to analyze incomplete data (using full information MLE rather than listwise deletion), obtain robust statistics (e.g., to account for nonnormality of continuous outcomes), or model discrete (binary or ordinal) outcomes (which require a threshold model, explained later in a chapter about categorical data) 2.3 Caveats with SEM 2.3.1 Model Comparison with OLS To test the \\(H_0\\) that the experimental manipulation (MOOD) explains \\(R^2=0\\)% of variance in POSitive thoughts, compare models that represent the \\(H_0\\) and \\(H_A\\) ols0 &lt;- lm(POS ~ 1, data = dat) ols1 &lt;- lm(POS ~ MOOD, data = dat) anova(ols0, ols1) ## Analysis of Variance Table ## ## Model 1: POS ~ 1 ## Model 2: POS ~ MOOD ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 99 6857.0 ## 2 98 4998.5 1 1858.6 36.439 2.819e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 This result matches the \\(F\\) test at the bottom of summary(ols1) 2.3.2 Model Comparison with lavaan Omitting variables from an SEM means they are removed from \\(\\bar{\\mathrm{y}}\\) and \\(S\\), returning a warning mle0 &lt;- sem(&#39;POS ~ 1&#39;, data = dat) mle1 &lt;- sem(&#39;POS ~ 1 + MOOD&#39;, data = dat) anova(mle0, mle1) ## ... models are based on a different set of observed variables Instead, keep predictor(s) in the model, but fix the slope(s) to zero mle0 &lt;- sem(&#39;POS ~ 1 + 0*MOOD&#39;, data = dat) anova(mle0, mle1) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## mle1 0 680.96 688.78 0.000 ## mle0 1 710.57 715.78 31.614 31.614 0.5533 1 1.88e-08 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.3.3 Moderation Caveats When evaluating moderation using a product term, that product term is a new variable in \\(\\bar{\\mathrm{y}}\\) and \\(S\\) e.g., we want to test MOOD’s effect, controlling for NFC before comparing adjusted group means, we should evaluate the homogeneity-of-slopes assumption As in formula objects, lavaan syntax recognizes the colon (:) operator but the asterisk (*) is reserved for assigning labels or values to parameters POS ~ 1 + MOOD + NFC + MOOD:NFC MOOD:NFC is now an additional variable in \\(\\bar{\\mathrm{y}}\\) and \\(S\\), so comparison to any model without that interaction term requires including the product term but fixing its effect to zero 2.3.3.1 Estimate and Test an Interaction with OLS ols.hom &lt;- lm(POS ~ MOOD + NFC, data = dat) ols.het &lt;- lm(POS ~ MOOD + NFC + MOOD:NFC, data = dat) anova(ols.hom, ols.het) ## Analysis of Variance Table ## ## Model 1: POS ~ MOOD + NFC ## Model 2: POS ~ MOOD + NFC + MOOD:NFC ## Res.Df RSS Df Sum of Sq F Pr(&gt;F) ## 1 97 4954.6 ## 2 96 4663.1 1 291.47 6.0005 0.01611 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Using ML estimation, model comparison would analogously yield an analysis of deviance a.k.a. likelihood ratio test (LRT) 2.3.3.2 Estimate and Test an Interaction with lavaan mle.hom &lt;- sem(&#39;POS ~ 1 + MOOD + NFC + 0*MOOD:NFC&#39;, data = dat) mle.het &lt;- sem(&#39;POS ~ 1 + MOOD + NFC + MOOD:NFC&#39;, data = dat) anova(mle.hom, mle.het) ## ## Chi-Squared Difference Test ## ## Df AIC BIC Chisq Chisq diff RMSEA Df diff Pr(&gt;Chisq) ## mle.het 0 678.01 691.04 0.0000 ## mle.hom 1 682.08 692.50 6.0629 6.0629 0.22501 1 0.0138 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 We can reject \\(H_0\\) of homogeneous NFC slopes across MOOD groups 2.3.3.3 Compare Adjusted Means Suppose we had failed to reject the \\(H_0\\) of homogeneity of slopes, and we wanted a single comparison of (adjusted) group means, controlling for NFC. MOOD is effect coded, so its slope (which is identical using OLS regression or SEM) is interpreted as the difference between a group’s mean and the grand mean half the group mean difference The \\(t\\) test (OLS) or Wald \\(z\\) test (SEM) is sufficient to test the \\(H_0: \\hat{\\mathrm{y}}_\\text{Treatment}|x = \\hat{\\mathrm{y}}_\\text{Control}|x\\) summary(mle.hom) ## lavaan 0.6.17.1884 ended normally after 19 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 4 ## ## Number of observations 100 ## ## Model Test User Model: ## ## Test statistic 6.063 ## Degrees of freedom 1 ## P-value (Chi-square) 0.014 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## POS ~ ## MOOD 4.326 0.704 6.145 0.000 ## NFC 0.474 0.504 0.941 0.346 ## MOOD:NFC 0.000 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS 0.000 0.704 0.000 1.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS 49.546 7.007 7.071 0.000 But the MOOD slope could also be fixed to zero (or dropped) to obtain a LRT from SEM (or \\(F\\) test from ANOVA). 2.3.4 Summary of Caveats SEMs are only comparable when they are fitted to the same data same observations (rows) and same variables (columns) Instead of removing predictors, fix slopes to zero Interaction terms are additional variables, added to \\(\\bar{\\mathrm{y}}\\) and \\(S\\) only compare models with same variables products of variables can be saved in the data.frame or specified using the colon (:) operator (e.g., x1:x2), not the asterisk (*) standardized solution is incorrect because it treats product terms as separate variables (e.g., if they were independently transformed to \\(z\\) scores rather than products of \\(z\\) scores) 2.4 Multigroup SEM 2.4.1 Group-Specific Intercepts in OLS Recall that omitting the intercepts allows each group to have a dummy code in the model slope0 &lt;- lm(POS ~ -1 + mood.f + NFC, data = dat) summary(slope0) ## ## Call: ## lm(formula = POS ~ -1 + mood.f + NFC, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.1713 -5.4855 -0.2585 4.5490 16.9279 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## mood.fneutral -4.3263 1.0109 -4.280 4.39e-05 *** ## mood.fpositive 4.3263 1.0109 4.280 4.39e-05 *** ## NFC 0.4743 0.5115 0.927 0.356 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.147 on 97 degrees of freedom ## Multiple R-squared: 0.2774, Adjusted R-squared: 0.2551 ## F-statistic: 12.42 on 3 and 97 DF, p-value: 6.115e-07 This still assumes homoskedasticity of residuals, and comparing intercepts (or adjusted means) requires the delta method, which is a way to estimate the SE of a function of parameters (e.g., difference between 2 slopes) from the SEs of the original parameter estimates. car::deltaMethod(slope0, &quot;b2 - b1&quot;, rhs = 0, parameterNames = paste0(&quot;b&quot;, 1:3)) ## Estimate SE 2.5 % 97.5 % Hypothesis z value Pr(&gt;|z|) ## b2 - b1 8.6527 1.4298 5.8504 11.4549 0.0000 6.0519 1.432e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 2.4.2 Group-Specific Intercepts in SEM? lavaan automatically uses the delta method when parameters are labeled in the model syntax (before * operator) model syntax includes user-defined parameters (:= operator) However, SEM cannot fit group-specific intercepts because they are linearly dependent (recall (multi)collinearity among predictors from a previously read regression text). That is, the positive-mood dummy code is simply 1 minus the neutral-mood dummy code, so they are perfectly (negatively) correlated. Therefore, \\(S\\) would not be positive definite, which is a term that indicates some redundancy among variables. This means that fitting a single-group SEM with group-specific intercepts is not possible: dat$treat &lt;- dat$mood.f == &quot;positive&quot; dat$control &lt;- 1 - dat$treat # linear dependency ## label slopes &quot;b1&quot; for neutral group, &quot;b2&quot; for positive group mod1 &lt;- &#39; POS ~ b1*mood.fneutral + b2*mood.fpositive + NFC ## user-defined parameter adj_mean_diff := b2 - b1 &#39; fit1 &lt;- sem(mod1, data = dat) # lavaan ERROR: ## sample covariance matrix is not positive-definite 2.4.3 Multiple Groups in SEM Rather than including MOOD as variable(s) in the model, we can fit the remainder of the model (POS ~ 1 + NFC) separately in each group each group gets unique parameter estimates constraints across groups can be added homoskedasticity of residuals homogeneous slopes MOOD’s effect is how group-specific intercepts differ each group gets unique parameter labels, in a vector below: POS ~ c(b1, b2)*1 use the same label for homogeneous slopes below: POS ~ c(b3, b3)*NFC mod2 &lt;- &#39; POS ~ c(b1, b2)*1 + c(b3, b3)*NFC ## user-defined parameter adj_M_diff := b2 - b1 &#39; fit2 &lt;- sem(mod2, data = dat, group = &quot;mood.f&quot;) summary(fit2) ## lavaan 0.6.17.1884 ended normally after 17 iterations ## ## Estimator ML ## Optimization method NLMINB ## Number of model parameters 6 ## Number of equality constraints 1 ## ## Number of observations per group: ## neutral 50 ## positive 50 ## ## Model Test User Model: ## ## Test statistic 6.037 ## Degrees of freedom 1 ## P-value (Chi-square) 0.014 ## Test statistic for each group: ## neutral 2.217 ## positive 3.820 ## ## Parameter Estimates: ## ## Standard errors Standard ## Information Expected ## Information saturated (h1) model Structured ## ## ## Group 1 [neutral]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## POS ~ ## NFC (b3) 0.443 0.502 0.882 0.378 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS (b1) -4.325 0.982 -4.404 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS 48.225 9.645 5.000 0.000 ## ## ## Group 2 [positive]: ## ## Regressions: ## Estimate Std.Err z-value P(&gt;|z|) ## POS ~ ## NFC (b3) 0.443 0.502 0.882 0.378 ## ## Intercepts: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS (b2) 4.325 1.009 4.288 0.000 ## ## Variances: ## Estimate Std.Err z-value P(&gt;|z|) ## .POS 50.870 10.174 5.000 0.000 ## ## Defined Parameters: ## Estimate Std.Err z-value P(&gt;|z|) ## adj_M_diff 8.651 1.408 6.143 0.000 ## compare to OLS, which assumes homoskedasticity summary(slope0) ## ## Call: ## lm(formula = POS ~ -1 + mood.f + NFC, data = dat) ## ## Residuals: ## Min 1Q Median 3Q Max ## -13.1713 -5.4855 -0.2585 4.5490 16.9279 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## mood.fneutral -4.3263 1.0109 -4.280 4.39e-05 *** ## mood.fpositive 4.3263 1.0109 4.280 4.39e-05 *** ## NFC 0.4743 0.5115 0.927 0.356 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 7.147 on 97 degrees of freedom ## Multiple R-squared: 0.2774, Adjusted R-squared: 0.2551 ## F-statistic: 12.42 on 3 and 97 DF, p-value: 6.115e-07 ## delta method to test adj_M_diff car::deltaMethod(slope0, &quot;b2 - b1&quot;, rhs = 0, parameterNames = paste0(&quot;b&quot;, 1:3)) ## Estimate SE 2.5 % 97.5 % Hypothesis z value Pr(&gt;|z|) ## b2 - b1 8.6527 1.4298 5.8504 11.4549 0.0000 6.0519 1.432e-09 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Note that the point and SE estimates from this delta-method result (using OLS) can differ from the corresponding results using SEM. Because SEM does not assume residual homoskedasticity, it may be more robust, but there is a trade-off because OLS is not biased by small samples the way that SEM is. 2.4.3.1 Summary Statistics for Multigroup SEM lavaan calculates summary statistics from the raw data= separately in each group, but lists can be passed directly gN # vector of sample sizes ## ## neutral positive ## 50 50 gM # mean vectors ## $neutral ## ATT NFC POS ## -4.7920520 0.0321142 -4.3110960 ## ## $positive ## ATT NFC POS ## 8.7534980 -0.0321146 4.3111040 gS # list of covariance matrices ## $neutral ## ATT NFC POS ## ATT 245.020884 4.812796 61.799307 ## NFC 4.812796 2.456274 -1.201971 ## POS 61.799307 -1.201971 47.663230 ## ## $positive ## ATT NFC POS ## ATT 231.2417228 0.8817017 56.235120 ## NFC 0.8817017 1.5276643 3.091531 ## POS 56.2351197 3.0915313 54.346483 fit2 &lt;- sem(mod2, sample.nobs = gN, # &quot;group=&quot; is implied by lists sample.mean = gM, sample.cov = gS) 2.4.3.2 Advantages of Multigroup SEM Less restrictive assumptions parameters differ by default More interpretable parameters each group has their own intercept and slopes Intuitive to specify \\(H_0\\) as user-defined parameter e.g., the difference between the intercepts in the treatment group (b2) and control group (b1) is zero Intuitive to represent assumptions about equality constraints by using the same labels across groups e.g., the same NFC effect (b3) testable by comparing models with(out) constraints Can easily test \\(H_0\\) about parameters other than means Are variances or correlations equal across groups? 2.4.3.3 Disadvantages: asymptotic assumption (large \\(N\\)) applies to each group single-group regression better in small samples "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
